{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb1dba1-27cc-471b-ac5e-8d59921bdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from distutils.dir_util import copy_tree\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import SortGraph\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (\n",
    "    ApplyConfig,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    RemoveStaticGraphInputs,\n",
    "    RemoveUnusedTensors,\n",
    ")\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.make_input_chanlast import MakeInputChannelsLast\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.util.config import extract_model_config_to_json\n",
    "from shutil import copy\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.analysis.fpgadataflow.op_and_param_counts import (\n",
    "    aggregate_dict_keys,\n",
    "    op_and_param_counts,\n",
    ")\n",
    "from finn.analysis.fpgadataflow.res_estimation import (\n",
    "    res_estimation,\n",
    "    res_estimation_complete,\n",
    ")\n",
    "from finn.builder.build_dataflow_config import (\n",
    "    DataflowBuildConfig,\n",
    "    DataflowOutputType,\n",
    "    ShellFlowType,\n",
    "    VerificationStepType,\n",
    ")\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "from finn.core.rtlsim_exec import rtlsim_exec\n",
    "from finn.core.throughput_test import throughput_test_rtlsim\n",
    "from finn.transformation.fpgadataflow.annotate_cycles import AnnotateCycles\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.transformation.fpgadataflow.derive_characteristic import (\n",
    "    DeriveCharacteristic,\n",
    "    DeriveFIFOSizes,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (\n",
    "    ReplaceVerilogRelPaths,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import (\n",
    "    InsertAndSetFIFODepths,\n",
    "    RemoveShallowFIFOs,\n",
    "    SplitLargeFIFOs,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from finn.transformation.fpgadataflow.synth_ooc import SynthOutOfContext\n",
    "from finn.transformation.fpgadataflow.vitis_build import VitisBuild\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.qonnx.quant_act_to_multithreshold import (\n",
    "    default_filter_function_generator,\n",
    ")\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.util.basic import (\n",
    "    get_rtlsim_trace_depth,\n",
    "    pyverilate_get_liveness_threshold_cycles,\n",
    ")\n",
    "from finn.util.pyverilator import verilator_fifosim\n",
    "from finn.util.test import execute_parent\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.util.pytorch import ToTensor\n",
    "from brevitas.onnx import export_qonnx\n",
    "\n",
    "from finn.transformation.fpgadataflow import convert_to_hw_layers as convert\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7333644c-ea70-453e-8d82-2425c996e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'streamlined_model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd89be9efe0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper('streamlined_model.onnx')\n",
    "showInNetron('streamlined_model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12c0cfec-edb0-4357-8f40-4701f97cb5b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import ConvertSubToAdd, ConvertDivToMul\n",
    "import finn.transformation.streamline.collapse_repeated as collapse\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "model = model.transform(convert.InferPool())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(convert.InferBinaryMatrixVectorActivation())\n",
    "\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59e313a7-ff83-4f45-a2bf-a4fea1a0793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f2fb62-42ea-4d52-a3ac-eaf85d075722",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07c3a7f7-c21f-4479-bad8-4746296a8018",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "515c6c05-ea59-4322-bc13-cc1ce4680dc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model_2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd89920c190>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model_2.onnx')\n",
    "showInNetron('model_2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4505f42b-9e3e-4ad5-9cfd-5305f4e226d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_: UINT32 -> UINT5 \n",
      "  warnings.warn(warn_str)\n"
     ]
    }
   ],
   "source": [
    "#model = model.transform(InferDataLayouts())\n",
    "#model = model.transform(RoundAndClipThresholds())\n",
    "#model = model.transform(convert.InferThresholdingLayer())\n",
    "\n",
    "#model = model.transform(RemoveCNVtoFCFlatten())\n",
    "#model = model.transform(InferDataLayouts())\n",
    "#model = model.transform(convert.InferLabelSelectLayer())\n",
    "\n",
    "#model = tidy_up(model)\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67034fb7-1d1d-492c-8a30-7d324ad5b25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('model_3.onnx')\n",
    "showInNetron('model_3.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bfdc7d-61dc-4ce8-9764-45c37af41eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808a46b4-9616-4c2d-8c42-8683fdd7eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'model_2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fd89be9f310>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "057ed98f-7394-46f5-b03e-f0461d031ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(model):\n",
    "\tinput_shape = model.get_tensor_shape(model.graph.input[0].name)\n",
    "\tpreproc = ToTensor()\n",
    "\texport_qonnx(preproc, torch.randn(input_shape), \"preproc.onnx\", opset_version = 11)\n",
    "\tqonnx_cleanup(\"preproc.onnx\", out_file = \"preproc.onnx\")\n",
    "\tpreproc_model = ModelWrapper(\"preproc.onnx\")\n",
    "\tpreproc_model = preproc_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "\tmodel = model.transform(MergeONNXModels(preproc_model))\n",
    "\tglobal_inp_name = model.graph.input[0].name\n",
    "\tmodel.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\tmodel = model.transform(InferShapes())\n",
    "\tmodel = model.transform(FoldConstants())\n",
    "\tmodel = model.transform(GiveUniqueNodeNames())\n",
    "\tmodel = model.transform(GiveReadableTensorNames())\n",
    "\tmodel = model.transform(InferDataTypes())\n",
    "\tmodel = model.transform(RemoveStaticGraphInputs())\n",
    "\treturn model\n",
    "\n",
    "def postprocessing(model):\n",
    "\tmodel = model.transform(InsertTopK(k=1))\n",
    "\tmodel = model.transform(InferShapes())\n",
    "\tmodel = model.transform(FoldConstants())\n",
    "\tmodel = model.transform(GiveUniqueNodeNames())\n",
    "\tmodel = model.transform(GiveReadableTensorNames())\n",
    "\tmodel = model.transform(InferDataTypes())\n",
    "\tmodel = model.transform(RemoveStaticGraphInputs())\n",
    "\treturn model\n",
    "\n",
    "def qonnx_to_finn(model):\n",
    "    \"\"\"\n",
    "    This step will only execute if QONNX nodes are found.\n",
    "    These include the following op_types: \"Quant\" , \"Trunc\" and \"BinaryQuant\".\n",
    "    If such nodes are found the step will run the tidy-up step from QONNX\n",
    "    and then convert the QONNX model to the FINN-ONNX dialect.\n",
    "    \"\"\"\n",
    "    # Check if any QONNX nodes exist, i.e. BinaryQuant, Quant or Trunc\n",
    "    q_count = 0\n",
    "    for op_type in [\"BinaryQuant\", \"Quant\", \"Trunc\"]:\n",
    "        q_count += len(model.get_nodes_by_op_type(op_type))\n",
    "    if q_count == 0:\n",
    "        return model\n",
    "\n",
    "    # QONNX cleanup\n",
    "    model = cleanup_model(model)\n",
    "    # QONNX to FINN-ONNX\n",
    "    model = model.transform(\n",
    "        ConvertQONNXtoFINN(\n",
    "            filter_function=default_filter_function_generator(\n",
    "                max_multithreshold_bit_width=8\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def tidy_up(model):\n",
    "    \"\"\"Run the tidy-up step on given model. This includes shape and datatype\n",
    "    inference, constant folding, and giving nodes and tensors better names.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "201175fe-6be9-42d8-b18e-7115d274c9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n",
      "Exported graph: graph(%input.1 : Float(1, 3, 224, 244, strides=[163968, 54656, 244, 1], requires_grad=0, device=cpu),\n",
      "      %fc.weight : Float(1000, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %fc.bias : Float(1000, strides=[1], requires_grad=1, device=cpu),\n",
      "      %onnx::Conv_204 : Float(64, 3, 7, 7, strides=[147, 49, 7, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_205 : Float(64, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_207 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_210 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_213 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_216 : Float(64, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_219 : Float(128, 64, 3, 3, strides=[576, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_220 : Float(128, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_222 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_225 : Float(128, 64, 1, 1, strides=[64, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_228 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_231 : Float(128, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_234 : Float(256, 128, 3, 3, strides=[1152, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_235 : Float(256, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_237 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_240 : Float(256, 128, 1, 1, strides=[128, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_243 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_246 : Float(256, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_249 : Float(512, 256, 3, 3, strides=[2304, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_250 : Float(512, strides=[1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_252 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_255 : Float(512, 256, 1, 1, strides=[256, 1, 1, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_258 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu),\n",
      "      %onnx::Conv_261 : Float(512, 512, 3, 3, strides=[4608, 9, 3, 1], requires_grad=0, device=cpu)):\n",
      "  %onnx::Conv_262 : Float(512, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_250)\n",
      "  %onnx::Conv_259 : Float(512, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_250)\n",
      "  %onnx::Conv_256 : Float(512, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_250)\n",
      "  %onnx::Conv_253 : Float(512, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_250)\n",
      "  %onnx::Conv_247 : Float(256, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_235)\n",
      "  %onnx::Conv_244 : Float(256, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_235)\n",
      "  %onnx::Conv_241 : Float(256, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_235)\n",
      "  %onnx::Conv_238 : Float(256, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_235)\n",
      "  %onnx::Conv_232 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_220)\n",
      "  %onnx::Conv_229 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_220)\n",
      "  %onnx::Conv_226 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_220)\n",
      "  %onnx::Conv_223 : Float(128, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_220)\n",
      "  %onnx::Conv_217 : Float(64, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_205)\n",
      "  %onnx::Conv_214 : Float(64, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_205)\n",
      "  %onnx::Conv_211 : Float(64, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_205)\n",
      "  %onnx::Conv_208 : Float(64, strides=[1], requires_grad=0, device=cpu) = onnx::Identity(%onnx::Conv_205)\n",
      "  %/conv1/Conv_output_0 : Float(1, 64, 112, 122, strides=[874496, 13664, 122, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[7, 7], pads=[3, 3, 3, 3], strides=[2, 2], onnx_name=\"/conv1/Conv\"](%input.1, %onnx::Conv_204, %onnx::Conv_205), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/relu/Relu_output_0 : Float(1, 64, 112, 122, strides=[874496, 13664, 122, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/relu/Relu\"](%/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/maxpool/MaxPool_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::MaxPool[ceil_mode=0, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/maxpool/MaxPool\"](%/relu/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.pooling.MaxPool2d::maxpool # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:780:0\n",
      "  %/layer1/layer1.0/conv1/Conv_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv1/Conv\"](%/maxpool/MaxPool_output_0, %onnx::Conv_207, %onnx::Conv_208), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer1/layer1.0/relu/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/relu/Relu\"](%/layer1/layer1.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer1/layer1.0/conv2/Conv_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.0/conv2/Conv\"](%/layer1/layer1.0/relu/Relu_output_0, %onnx::Conv_210, %onnx::Conv_211), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer1/layer1.0/relu_1/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/relu_1/Relu\"](%/layer1/layer1.0/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer1/layer1.0/Add_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.0/Add\"](%/layer1/layer1.0/relu_1/Relu_output_0, %/maxpool/MaxPool_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer1/layer1.0/relu_2/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.0/relu_2/Relu\"](%/layer1/layer1.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer1/layer1.1/conv1/Conv_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv1/Conv\"](%/layer1/layer1.0/relu_2/Relu_output_0, %onnx::Conv_213, %onnx::Conv_214), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer1/layer1.1/relu/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/relu/Relu\"](%/layer1/layer1.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer1/layer1.1/conv2/Conv_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer1/layer1.1/conv2/Conv\"](%/layer1/layer1.1/relu/Relu_output_0, %onnx::Conv_216, %onnx::Conv_217), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer1/layer1.1/relu_1/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/relu_1/Relu\"](%/layer1/layer1.1/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer1/layer1.1/Add_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer1/layer1.1/Add\"](%/layer1/layer1.1/relu_1/Relu_output_0, %/layer1/layer1.0/relu_2/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer1/layer1.1/relu_2/Relu_output_0 : Float(1, 64, 56, 61, strides=[218624, 3416, 61, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer1/layer1.1/relu_2/Relu\"](%/layer1/layer1.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer1/torchvision.models.resnet.BasicBlock::layer1.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.0/conv1/Conv_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer2/layer2.0/conv1/Conv\"](%/layer1/layer1.1/relu_2/Relu_output_0, %onnx::Conv_219, %onnx::Conv_220), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer2/layer2.0/relu/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu/Relu\"](%/layer2/layer2.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.0/conv2/Conv_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.0/conv2/Conv\"](%/layer2/layer2.0/relu/Relu_output_0, %onnx::Conv_222, %onnx::Conv_223), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer2/layer2.0/relu_1/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu_1/Relu\"](%/layer2/layer2.0/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.0/downsample/downsample.0/Conv_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer2/layer2.0/downsample/downsample.0/Conv\"](%/layer1/layer1.1/relu_2/Relu_output_0, %onnx::Conv_225, %onnx::Conv_226), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer2/layer2.0/relu_2/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu_2/Relu\"](%/layer2/layer2.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.0/Add_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.0/Add\"](%/layer2/layer2.0/relu_1/Relu_output_0, %/layer2/layer2.0/relu_2/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer2/layer2.0/relu_3/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.0/relu_3/Relu\"](%/layer2/layer2.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.1/conv1/Conv_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv1/Conv\"](%/layer2/layer2.0/relu_3/Relu_output_0, %onnx::Conv_228, %onnx::Conv_229), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer2/layer2.1/relu/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/relu/Relu\"](%/layer2/layer2.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.1/conv2/Conv_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer2/layer2.1/conv2/Conv\"](%/layer2/layer2.1/relu/Relu_output_0, %onnx::Conv_231, %onnx::Conv_232), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer2/layer2.1/relu_1/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/relu_1/Relu\"](%/layer2/layer2.1/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer2/layer2.1/Add_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer2/layer2.1/Add\"](%/layer2/layer2.1/relu_1/Relu_output_0, %/layer2/layer2.0/relu_3/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer2/layer2.1/relu_2/Relu_output_0 : Float(1, 128, 28, 31, strides=[111104, 868, 31, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer2/layer2.1/relu_2/Relu\"](%/layer2/layer2.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer2/torchvision.models.resnet.BasicBlock::layer2.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.0/conv1/Conv_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer3/layer3.0/conv1/Conv\"](%/layer2/layer2.1/relu_2/Relu_output_0, %onnx::Conv_234, %onnx::Conv_235), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer3/layer3.0/relu/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu/Relu\"](%/layer3/layer3.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.0/conv2/Conv_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.0/conv2/Conv\"](%/layer3/layer3.0/relu/Relu_output_0, %onnx::Conv_237, %onnx::Conv_238), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer3/layer3.0/relu_1/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu_1/Relu\"](%/layer3/layer3.0/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.0/downsample/downsample.0/Conv_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer3/layer3.0/downsample/downsample.0/Conv\"](%/layer2/layer2.1/relu_2/Relu_output_0, %onnx::Conv_240, %onnx::Conv_241), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer3/layer3.0/relu_2/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu_2/Relu\"](%/layer3/layer3.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.0/Add_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.0/Add\"](%/layer3/layer3.0/relu_1/Relu_output_0, %/layer3/layer3.0/relu_2/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer3/layer3.0/relu_3/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.0/relu_3/Relu\"](%/layer3/layer3.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.1/conv1/Conv_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv1/Conv\"](%/layer3/layer3.0/relu_3/Relu_output_0, %onnx::Conv_243, %onnx::Conv_244), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer3/layer3.1/relu/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/relu/Relu\"](%/layer3/layer3.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.1/conv2/Conv_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer3/layer3.1/conv2/Conv\"](%/layer3/layer3.1/relu/Relu_output_0, %onnx::Conv_246, %onnx::Conv_247), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer3/layer3.1/relu_1/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/relu_1/Relu\"](%/layer3/layer3.1/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer3/layer3.1/Add_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer3/layer3.1/Add\"](%/layer3/layer3.1/relu_1/Relu_output_0, %/layer3/layer3.0/relu_3/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer3/layer3.1/relu_2/Relu_output_0 : Float(1, 256, 14, 16, strides=[57344, 224, 16, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer3/layer3.1/relu_2/Relu\"](%/layer3/layer3.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer3/torchvision.models.resnet.BasicBlock::layer3.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.0/conv1/Conv_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[2, 2], onnx_name=\"/layer4/layer4.0/conv1/Conv\"](%/layer3/layer3.1/relu_2/Relu_output_0, %onnx::Conv_249, %onnx::Conv_250), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer4/layer4.0/relu/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu/Relu\"](%/layer4/layer4.0/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.0/conv2/Conv_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.0/conv2/Conv\"](%/layer4/layer4.0/relu/Relu_output_0, %onnx::Conv_252, %onnx::Conv_253), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer4/layer4.0/relu_1/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu_1/Relu\"](%/layer4/layer4.0/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.0/downsample/downsample.0/Conv_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[1, 1], pads=[0, 0, 0, 0], strides=[2, 2], onnx_name=\"/layer4/layer4.0/downsample/downsample.0/Conv\"](%/layer3/layer3.1/relu_2/Relu_output_0, %onnx::Conv_255, %onnx::Conv_256), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.container.Sequential::downsample/torch.nn.modules.conv.Conv2d::downsample.0 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer4/layer4.0/relu_2/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu_2/Relu\"](%/layer4/layer4.0/downsample/downsample.0/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.0/Add_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.0/Add\"](%/layer4/layer4.0/relu_1/Relu_output_0, %/layer4/layer4.0/relu_2/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer4/layer4.0/relu_3/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.0/relu_3/Relu\"](%/layer4/layer4.0/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.0/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.1/conv1/Conv_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv1/Conv\"](%/layer4/layer4.0/relu_3/Relu_output_0, %onnx::Conv_258, %onnx::Conv_259), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv1 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer4/layer4.1/relu/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/relu/Relu\"](%/layer4/layer4.1/conv1/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.1/conv2/Conv_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Conv[dilations=[1, 1], group=1, kernel_shape=[3, 3], pads=[1, 1, 1, 1], strides=[1, 1], onnx_name=\"/layer4/layer4.1/conv2/Conv\"](%/layer4/layer4.1/relu/Relu_output_0, %onnx::Conv_261, %onnx::Conv_262), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.conv.Conv2d::conv2 # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:458:0\n",
      "  %/layer4/layer4.1/relu_1/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/relu_1/Relu\"](%/layer4/layer4.1/conv2/Conv_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/layer4/layer4.1/Add_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Add[onnx_name=\"/layer4/layer4.1/Add\"](%/layer4/layer4.1/relu_1/Relu_output_0, %/layer4/layer4.0/relu_3/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1 # /tmp/ipykernel_156/975089009.py:32:0\n",
      "  %/layer4/layer4.1/relu_2/Relu_output_0 : Float(1, 512, 7, 8, strides=[28672, 56, 8, 1], requires_grad=1, device=cpu) = onnx::Relu[onnx_name=\"/layer4/layer4.1/relu_2/Relu\"](%/layer4/layer4.1/Add_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.container.Sequential::layer4/torchvision.models.resnet.BasicBlock::layer4.1/torch.nn.modules.activation.ReLU::relu # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1453:0\n",
      "  %/avgpool/GlobalAveragePool_output_0 : Float(1, 512, 1, 1, strides=[512, 1, 1, 1], requires_grad=1, device=cpu) = onnx::GlobalAveragePool[onnx_name=\"/avgpool/GlobalAveragePool\"](%/layer4/layer4.1/relu_2/Relu_output_0), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.pooling.AdaptiveAvgPool2d::avgpool # /usr/local/lib/python3.10/dist-packages/torch/nn/functional.py:1213:0\n",
      "  %/Flatten_output_0 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Flatten[axis=1, onnx_name=\"/Flatten\"](%/avgpool/GlobalAveragePool_output_0), scope: torchvision.models.resnet.ResNet:: # /usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py:273:0\n",
      "  %202 : Float(1, 1000, strides=[1000, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1, onnx_name=\"/fc/Gemm\"](%/Flatten_output_0, %fc.weight, %fc.bias), scope: torchvision.models.resnet.ResNet::/torch.nn.modules.linear.Linear::fc # /usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114:0\n",
      "  return (%202)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from torchvision.models.resnet import BasicBlock, Bottleneck\n",
    "from torch import Tensor\n",
    "\n",
    "# Load the original ResNet model\n",
    "original_resnet = models.resnet18()\n",
    "#original_resnet.train()\n",
    "\n",
    "def add_relu_after_bn():\n",
    "    BasicBlock.forward = basic_block_forward\n",
    "    '''\n",
    "    module_output = module\n",
    "    if isinstance(module, nn.BatchNorm2d) and (name == \"bn2\" or name == \"bn3\"):\n",
    "        module_output = nn.Sequential(module, nn.ReLU())\n",
    "    for name, child in module.named_children():\n",
    "        module_output.add_module(name, add_relu_after_bn(name, child))\n",
    "    del module\n",
    "\n",
    "    return module_output\n",
    "    '''\n",
    "\n",
    "\n",
    "def basic_block_forward(self, x: Tensor) -> Tensor:\n",
    "    identity = x\n",
    "    out = self.conv1(x)\n",
    "    out = self.bn1(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    out = self.conv2(out)\n",
    "    out = self.bn2(out)\n",
    "    out = self.relu(out)\n",
    "\n",
    "    if self.downsample is not None:\n",
    "        identity = self.relu(self.downsample(x))\n",
    "\n",
    "    out = out + identity\n",
    "    out = self.relu(out)\n",
    "\n",
    "    return out\n",
    "    \n",
    "# Create a custom ResNet with ReLU inserted before addition operations\n",
    "add_relu_after_bn()\n",
    "\n",
    "print(original_resnet)\n",
    "name = f'model_with_relus.onnx'\n",
    "torch.onnx.export(original_resnet, ref_input, name, export_params=True, verbose = True, opset_version=11)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64d8e879-c9dd-46a5-8f3b-2af31c8deb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model_with_relus.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f855a11f610>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('model_with_relus.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "532ab407-950a-496a-8f13-64489e861484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model_1.0_0.0.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f859806fdf0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "showInNetron('model_1.0_0.0.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "89642c6d-f651-463a-874c-f6bf48e2d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model_1.0_0.0_quant.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f858b91a950>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper('model_1.0_0.0_quant.onnx')\n",
    "showInNetron('model_1.0_0.0_quant.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8f9927b6-b366-4c6e-a365-11e14873a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n",
      "/srv/homes/ipanagou/thesis/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 11. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f858b91b910>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = preprocessing(model)\n",
    "model = postprocessing(model)\n",
    "model = model.transform(MakeInputChannelsLast())\n",
    "model = tidy_up(model)\n",
    "model = qonnx_to_finn(model)\n",
    "model = tidy_up(model)\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4b9de4e8-d78a-4425-b4cf-c6a90b5f59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found topk node\n",
      "found Mul node\n",
      "0.26739833\n",
      "it is actually scalar\n",
      "found topk node\n",
      "found topk node\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f855a155e10>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streamlining\n",
    "\n",
    "from qonnx.transformation.general import ConvertSubToAdd, ConvertDivToMul\n",
    "import finn.transformation.streamline.collapse_repeated as collapse\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "model = model.transform(ConvertSubToAdd())\n",
    "model = model.transform(ConvertDivToMul())\n",
    "model = model.transform(collapse.CollapseRepeatedMul())\n",
    "model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "\n",
    "model = model.transform(reorder.MoveMulPastMaxPool())\n",
    "model = model.transform(reorder.MoveLinearPastFork())\n",
    "model = model.transform(reorder.MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(reorder.MoveScalarMulPastConv())\n",
    "model = model.transform(reorder.MoveScalarMulPastMatMul())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants()) # for the mul before the global average pool\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7b375368-73fd-44cd-bed5-20467a14c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8\n",
      "-128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_4: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_7: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_11: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_14: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_18: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_21: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_25: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_28: UINT32 -> UINT9 \n",
      "  warnings.warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f855a14fca0>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO HW\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "model = model.transform(convert.InferPool())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "\n",
    "model = tidy_up(model)\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f12a0baf-9998-4ea8-9cd2-f1fe965692c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found topk node\n"
     ]
    }
   ],
   "source": [
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e19e491-b8fd-42c1-8cb2-db777b67b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff579033e50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94f757fc-9f61-4ec4-9dc6-1ea29faf5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "streamlined = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "080b312d-3de0-48a1-b79e-644bd85e89d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff575787df0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(InferDataLayouts()) # infer data layouts is a lifesaver\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1b03bc0-c247-462b-9d87-2784924c3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff574916830>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(convert.InferPool())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7836196e-9a36-4d8f-a93a-83db63803653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5788b2fb0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7dcecb9e-318d-43e2-97dd-7a76027483de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5748084c0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea5af60b-8269-4f33-9a4a-0455867e662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57480ac50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "843487b3-fa6d-40d2-82de-33fae8f08b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8\n",
      "-128\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57480ba00>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "543186df-d8db-41fe-b610-42e4347b6744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43ea2af1-6dfd-4cd6-b2ad-f187c98b7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "87d41004-dc89-4f07-871b-c75e02901ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec95fc36-65e5-4e93-931a-2ccff9878048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dabb2305-0ed1-4b2a-acf6-5e0213717844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5754cfb20>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d525af5-055b-46c8-bb75-3f5dce97b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff7524d1ae0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9bf2e596-91bd-4120-9853-3a8adb58f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff575668910>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "edd6c99b-be48-4e74-b936-8ef6798a7786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_11: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_18: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_25: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5747e7880>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57527cc3-c082-4012-b9c4-c94b26e1f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff7524d31f0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d9448518-4a80-4451-a195-75ba06084f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"Thresholding_3_out0\"\n",
      "input: \"DuplicateStreams_0_out1\"\n",
      "output: \"Add_0_out0\"\n",
      "name: \"Add_0\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_6_out0\"\n",
      "input: \"DuplicateStreams_1_out1\"\n",
      "output: \"Add_1_out0\"\n",
      "name: \"Add_1\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_13_out0\"\n",
      "input: \"DuplicateStreams_3_out1\"\n",
      "output: \"Add_2_out0\"\n",
      "name: \"Add_2\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_20_out0\"\n",
      "input: \"DuplicateStreams_5_out1\"\n",
      "output: \"Add_3_out0\"\n",
      "name: \"Add_3\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_27_out0\"\n",
      "input: \"DuplicateStreams_7_out1\"\n",
      "output: \"Add_4_out0\"\n",
      "name: \"Add_4\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff577eb5270>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tidy_up(model)\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8119f-07c2-4b1b-a2a8-6f9646380587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb1906-5007-4736-8702-1d5a98ef60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6bfa3-bcd6-4b9a-8e1e-1a7977c61e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da744171-26d2-46d4-bfde-6b27410579bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4b716-5672-47d3-b287-c522498022ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26de2f-5479-4413-874f-c17e6c28bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d84a8-a8fd-4b74-84a9-c83eda169208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(convert.InferPool())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb57a8e-3671-4f5a-aebc-4d44a4745219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a20d9-3fee-4b5d-80cd-d5946c87a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdcb642-8a07-4d82-aed6-e85108bf842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a1c03-a79c-4765-838e-a004755879f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd5b17-5dac-4920-ab7c-adb3c7bfb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0feb1-d49a-4179-8325-a72529fe65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3bf3e-4b05-4d24-a9d9-6a59c4398663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
