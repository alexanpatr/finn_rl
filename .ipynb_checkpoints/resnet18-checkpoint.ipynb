{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb1dba1-27cc-471b-ac5e-8d59921bdd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from distutils.dir_util import copy_tree\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import SortGraph\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (\n",
    "    ApplyConfig,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    RemoveStaticGraphInputs,\n",
    "    RemoveUnusedTensors,\n",
    ")\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.make_input_chanlast import MakeInputChannelsLast\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.util.config import extract_model_config_to_json\n",
    "from shutil import copy\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.analysis.fpgadataflow.op_and_param_counts import (\n",
    "    aggregate_dict_keys,\n",
    "    op_and_param_counts,\n",
    ")\n",
    "from finn.analysis.fpgadataflow.res_estimation import (\n",
    "    res_estimation,\n",
    "    res_estimation_complete,\n",
    ")\n",
    "from finn.builder.build_dataflow_config import (\n",
    "    DataflowBuildConfig,\n",
    "    DataflowOutputType,\n",
    "    ShellFlowType,\n",
    "    VerificationStepType,\n",
    ")\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "from finn.core.rtlsim_exec import rtlsim_exec\n",
    "from finn.core.throughput_test import throughput_test_rtlsim\n",
    "from finn.transformation.fpgadataflow.annotate_cycles import AnnotateCycles\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.transformation.fpgadataflow.derive_characteristic import (\n",
    "    DeriveCharacteristic,\n",
    "    DeriveFIFOSizes,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (\n",
    "    ReplaceVerilogRelPaths,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import (\n",
    "    InsertAndSetFIFODepths,\n",
    "    RemoveShallowFIFOs,\n",
    "    SplitLargeFIFOs,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from finn.transformation.fpgadataflow.synth_ooc import SynthOutOfContext\n",
    "from finn.transformation.fpgadataflow.vitis_build import VitisBuild\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.qonnx.quant_act_to_multithreshold import (\n",
    "    default_filter_function_generator,\n",
    ")\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.util.basic import (\n",
    "    get_rtlsim_trace_depth,\n",
    "    pyverilate_get_liveness_threshold_cycles,\n",
    ")\n",
    "from finn.util.pyverilator import verilator_fifosim\n",
    "from finn.util.test import execute_parent\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.util.pytorch import ToTensor\n",
    "from brevitas.onnx import export_qonnx\n",
    "\n",
    "from finn.transformation.fpgadataflow import convert_to_hw_layers as convert\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7333644c-ea70-453e-8d82-2425c996e4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving '/srv/homes/ipanagou/thesis/finn_dev_ipanagou/LeNet5/intermediate_models/step_tidy_up.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f06982606d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper('/srv/homes/ipanagou/thesis/finn_dev_ipanagou/LeNet5/intermediate_models/step_tidy_up.onnx')\n",
    "showInNetron('/srv/homes/ipanagou/thesis/finn_dev_ipanagou/LeNet5/intermediate_models/step_tidy_up.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f952aa61-80f5-4713-9810-c55038412aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.transformation.general import ConvertSubToAdd, ConvertDivToMul\n",
    "import finn.transformation.streamline.collapse_repeated as collapse\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "model = model.transform(ConvertSubToAdd())\n",
    "model = model.transform(ConvertDivToMul())\n",
    "model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(reorder.MoveMulPastMaxPool())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(reorder.MoveScalarMulPastConv())\n",
    "model = model.transform(reorder.MoveScalarMulPastMatMul())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd7e7f1a-904b-41e7-9e08-23645362b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(collapse.CollapseRepeatedMul())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff5ac44-0522-40a6-98f4-985e069019ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f04b24bc4c0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f0ed9ce-6dde-4ceb-81c7-71edabd0a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('172.17.0.1', 35654)\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 683, in process_request_thread\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"/usr/lib/python3.10/http/server.py\", line 433, in handle\n",
      "    self.handle_one_request()\n",
      "  File \"/usr/lib/python3.10/http/server.py\", line 421, in handle_one_request\n",
      "    method()\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/netron/server.py\", line 106, in do_GET\n",
      "    self._write(status_code, content_type, content)\n",
      "  File \"/usr/local/lib/python3.10/dist-packages/netron/server.py\", line 119, in _write\n",
      "    self.wfile.write(content)\n",
      "  File \"/usr/lib/python3.10/socketserver.py\", line 826, in write\n",
      "    self._sock.sendall(b)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "model = model.transform(ConvertSubToAdd())\n",
    "model = model.transform(ConvertDivToMul())\n",
    "model = model.transform(collapse.CollapseRepeatedMul())\n",
    "model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(absorb.Absorb1BitMulIntoConv())\n",
    "model = model.transform(absorb.Absorb1BitMulIntoMatMul())\n",
    "\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "\n",
    "model = model.transform(reorder.MoveMulPastMaxPool())\n",
    "model = model.transform(reorder.MoveLinearPastFork())\n",
    "model = model.transform(reorder.MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(reorder.MoveScalarMulPastConv())\n",
    "model = model.transform(reorder.MoveScalarMulPastMatMul())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants()) # for the mul before the global average pool\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RemoveUnusedTensors())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0eee6b45-0f49-4cc3-a9ac-82a811003557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f672ea47a30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e37eb1a9-9a57-4b76-bc26-ab8150016470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ModelWrapper(\"model.onnx\")\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(convert.InferBinaryMatrixVectorActivation())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "for i in range(8):\n",
    "    model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    model = model.transform(reorder.MoveTransposePastFork())\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4b2612fb-165a-471c-b77b-9d5dadf07f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    model = model.transform(reorder.MoveTransposePastFork())\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da559da8-9c98-4ecb-b9cc-231c95ff64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2):\n",
    "    model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    model = model.transform(reorder.MoveTransposePastFork())\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4682d392-5d37-41ae-87e5-f3654ca2148c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model2.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f687821b730>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())\n",
    "model.save('model2.onnx')\n",
    "showInNetron('model2.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539a25bc-7456-4475-83e7-6800e0a2d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "for i in range(4):\n",
    "    model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "    model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "    model = model.transform(reorder.MoveTransposePastFork())\n",
    "    model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
