{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeb1dba1-27cc-471b-ac5e-8d59921bdd62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import onnx\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "from copy import deepcopy\n",
    "from distutils.dir_util import copy_tree\n",
    "from qonnx.core.modelwrapper import ModelWrapper\n",
    "from qonnx.transformation.general import SortGraph\n",
    "from qonnx.transformation.merge_onnx_models import MergeONNXModels\n",
    "from qonnx.transformation.insert_topk import InsertTopK\n",
    "from qonnx.core.datatype import DataType\n",
    "from qonnx.custom_op.registry import getCustomOp\n",
    "from qonnx.transformation.bipolar_to_xnor import ConvertBipolarMatMulToXnorPopcount\n",
    "from qonnx.transformation.fold_constants import FoldConstants\n",
    "from qonnx.transformation.general import (\n",
    "    ApplyConfig,\n",
    "    GiveReadableTensorNames,\n",
    "    GiveUniqueNodeNames,\n",
    "    RemoveStaticGraphInputs,\n",
    "    RemoveUnusedTensors,\n",
    ")\n",
    "from qonnx.transformation.infer_data_layouts import InferDataLayouts\n",
    "from qonnx.transformation.infer_datatypes import InferDataTypes\n",
    "from qonnx.transformation.infer_shapes import InferShapes\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from qonnx.transformation.make_input_chanlast import MakeInputChannelsLast\n",
    "from qonnx.util.cleanup import cleanup as qonnx_cleanup\n",
    "from qonnx.util.cleanup import cleanup_model\n",
    "from qonnx.util.config import extract_model_config_to_json\n",
    "from shutil import copy\n",
    "\n",
    "import finn.transformation.fpgadataflow.convert_to_hw_layers as to_hw\n",
    "import finn.transformation.streamline.absorb as absorb\n",
    "from finn.analysis.fpgadataflow.dataflow_performance import dataflow_performance\n",
    "from finn.analysis.fpgadataflow.exp_cycles_per_layer import exp_cycles_per_layer\n",
    "from finn.analysis.fpgadataflow.hls_synth_res_estimation import hls_synth_res_estimation\n",
    "from finn.analysis.fpgadataflow.op_and_param_counts import (\n",
    "    aggregate_dict_keys,\n",
    "    op_and_param_counts,\n",
    ")\n",
    "from finn.analysis.fpgadataflow.res_estimation import (\n",
    "    res_estimation,\n",
    "    res_estimation_complete,\n",
    ")\n",
    "from finn.builder.build_dataflow_config import (\n",
    "    DataflowBuildConfig,\n",
    "    DataflowOutputType,\n",
    "    ShellFlowType,\n",
    "    VerificationStepType,\n",
    ")\n",
    "from finn.core.onnx_exec import execute_onnx\n",
    "from finn.core.rtlsim_exec import rtlsim_exec\n",
    "from finn.core.throughput_test import throughput_test_rtlsim\n",
    "from finn.transformation.fpgadataflow.annotate_cycles import AnnotateCycles\n",
    "from finn.transformation.fpgadataflow.compile_cppsim import CompileCppSim\n",
    "from finn.transformation.fpgadataflow.create_dataflow_partition import (\n",
    "    CreateDataflowPartition,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.create_stitched_ip import CreateStitchedIP\n",
    "from finn.transformation.fpgadataflow.derive_characteristic import (\n",
    "    DeriveCharacteristic,\n",
    "    DeriveFIFOSizes,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.hlssynth_ip import HLSSynthIP\n",
    "from finn.transformation.fpgadataflow.insert_dwc import InsertDWC\n",
    "from finn.transformation.fpgadataflow.insert_fifo import InsertFIFO\n",
    "from finn.transformation.fpgadataflow.make_pynq_driver import MakePYNQDriver\n",
    "from finn.transformation.fpgadataflow.make_zynq_proj import ZynqBuild\n",
    "from finn.transformation.fpgadataflow.minimize_accumulator_width import (\n",
    "    MinimizeAccumulatorWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.minimize_weight_bit_width import (\n",
    "    MinimizeWeightBitWidth,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.prepare_cppsim import PrepareCppSim\n",
    "from finn.transformation.fpgadataflow.prepare_ip import PrepareIP\n",
    "from finn.transformation.fpgadataflow.prepare_rtlsim import PrepareRTLSim\n",
    "from finn.transformation.fpgadataflow.replace_verilog_relpaths import (\n",
    "    ReplaceVerilogRelPaths,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_exec_mode import SetExecMode\n",
    "from finn.transformation.fpgadataflow.set_fifo_depths import (\n",
    "    InsertAndSetFIFODepths,\n",
    "    RemoveShallowFIFOs,\n",
    "    SplitLargeFIFOs,\n",
    ")\n",
    "from finn.transformation.fpgadataflow.set_folding import SetFolding\n",
    "from finn.transformation.fpgadataflow.specialize_layers import SpecializeLayers\n",
    "from finn.transformation.fpgadataflow.synth_ooc import SynthOutOfContext\n",
    "from finn.transformation.fpgadataflow.vitis_build import VitisBuild\n",
    "from finn.transformation.move_reshape import RemoveCNVtoFCFlatten\n",
    "from finn.transformation.qonnx.convert_qonnx_to_finn import ConvertQONNXtoFINN\n",
    "from finn.transformation.qonnx.quant_act_to_multithreshold import (\n",
    "    default_filter_function_generator,\n",
    ")\n",
    "from finn.transformation.streamline import Streamline\n",
    "from finn.transformation.streamline.reorder import MakeMaxPoolNHWC\n",
    "from finn.util.basic import (\n",
    "    get_rtlsim_trace_depth,\n",
    "    pyverilate_get_liveness_threshold_cycles,\n",
    ")\n",
    "from finn.util.pyverilator import verilator_fifosim\n",
    "from finn.util.test import execute_parent\n",
    "\n",
    "from finn.util.visualization import showInNetron\n",
    "from finn.util.pytorch import ToTensor\n",
    "from brevitas.onnx import export_qonnx\n",
    "\n",
    "from finn.transformation.fpgadataflow import convert_to_hw_layers as convert\n",
    "from qonnx.transformation.lower_convs_to_matmul import LowerConvsToMatMul\n",
    "from finn.transformation.streamline.round_thresholds import RoundAndClipThresholds\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "057ed98f-7394-46f5-b03e-f0461d031ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(model):\n",
    "\tinput_shape = model.get_tensor_shape(model.graph.input[0].name)\n",
    "\tpreproc = ToTensor()\n",
    "\texport_qonnx(preproc, torch.randn(input_shape), \"preproc.onnx\", opset_version = 11)\n",
    "\tqonnx_cleanup(\"preproc.onnx\", out_file = \"preproc.onnx\")\n",
    "\tpreproc_model = ModelWrapper(\"preproc.onnx\")\n",
    "\tpreproc_model = preproc_model.transform(ConvertQONNXtoFINN())\n",
    "\n",
    "\tmodel = model.transform(MergeONNXModels(preproc_model))\n",
    "\tglobal_inp_name = model.graph.input[0].name\n",
    "\tmodel.set_tensor_datatype(global_inp_name, DataType[\"UINT8\"])\n",
    "\tmodel = model.transform(InferShapes())\n",
    "\tmodel = model.transform(FoldConstants())\n",
    "\tmodel = model.transform(GiveUniqueNodeNames())\n",
    "\tmodel = model.transform(GiveReadableTensorNames())\n",
    "\tmodel = model.transform(InferDataTypes())\n",
    "\tmodel = model.transform(RemoveStaticGraphInputs())\n",
    "\treturn model\n",
    "\n",
    "def postprocessing(model):\n",
    "\tmodel = model.transform(InsertTopK(k=1))\n",
    "\tmodel = model.transform(InferShapes())\n",
    "\tmodel = model.transform(FoldConstants())\n",
    "\tmodel = model.transform(GiveUniqueNodeNames())\n",
    "\tmodel = model.transform(GiveReadableTensorNames())\n",
    "\tmodel = model.transform(InferDataTypes())\n",
    "\tmodel = model.transform(RemoveStaticGraphInputs())\n",
    "\treturn model\n",
    "\n",
    "def qonnx_to_finn(model):\n",
    "    \"\"\"\n",
    "    This step will only execute if QONNX nodes are found.\n",
    "    These include the following op_types: \"Quant\" , \"Trunc\" and \"BinaryQuant\".\n",
    "    If such nodes are found the step will run the tidy-up step from QONNX\n",
    "    and then convert the QONNX model to the FINN-ONNX dialect.\n",
    "    \"\"\"\n",
    "    # Check if any QONNX nodes exist, i.e. BinaryQuant, Quant or Trunc\n",
    "    q_count = 0\n",
    "    for op_type in [\"BinaryQuant\", \"Quant\", \"Trunc\"]:\n",
    "        q_count += len(model.get_nodes_by_op_type(op_type))\n",
    "    if q_count == 0:\n",
    "        return model\n",
    "\n",
    "    # QONNX cleanup\n",
    "    model = cleanup_model(model)\n",
    "    # QONNX to FINN-ONNX\n",
    "    model = model.transform(\n",
    "        ConvertQONNXtoFINN(\n",
    "            filter_function=default_filter_function_generator(\n",
    "                max_multithreshold_bit_width=8\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    return model\n",
    "\n",
    "\n",
    "def tidy_up(model):\n",
    "    \"\"\"Run the tidy-up step on given model. This includes shape and datatype\n",
    "    inference, constant folding, and giving nodes and tensors better names.\n",
    "    \"\"\"\n",
    "\n",
    "    model = model.transform(InferShapes())\n",
    "    model = model.transform(FoldConstants())\n",
    "    model = model.transform(GiveUniqueNodeNames())\n",
    "    model = model.transform(GiveReadableTensorNames())\n",
    "    model = model.transform(InferDataTypes())\n",
    "    model = model.transform(RemoveStaticGraphInputs())\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "89642c6d-f651-463a-874c-f6bf48e2d97a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model_1.0_0.0_quant.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f84a5664280>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ModelWrapper('model_1.0_0.0_quant.onnx')\n",
    "showInNetron('model_1.0_0.0_quant.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f9927b6-b366-4c6e-a365-11e14873a2b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/deps/qonnx/src/qonnx/transformation/infer_data_layouts.py:127: UserWarning: Assuming 4D input is NCHW\n",
      "  warnings.warn(\"Assuming 4D input is NCHW\")\n",
      "/srv/homes/ipanagou/thesis/finn/deps/qonnx/src/qonnx/transformation/gemm_to_matmul.py:57: UserWarning: The GemmToMatMul transformation only offers explicit support for version 9 of the Gemm node, but the ONNX version of the supplied model is 11. Thus the transformation may fail or return incomplete results.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f84a53c6c80>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = preprocessing(model)\n",
    "model = postprocessing(model)\n",
    "model = model.transform(MakeInputChannelsLast())\n",
    "model = tidy_up(model)\n",
    "model = qonnx_to_finn(model)\n",
    "model = tidy_up(model)\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b9de4e8-d78a-4425-b4cf-c6a90b5f59e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found topk node\n",
      "found Mul node\n",
      "0.58210987\n",
      "it is actually scalar\n",
      "found topk node\n",
      "found topk node\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f84a5629270>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Streamlining\n",
    "\n",
    "from qonnx.transformation.general import ConvertSubToAdd, ConvertDivToMul\n",
    "import finn.transformation.streamline.collapse_repeated as collapse\n",
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "model = model.transform(ConvertSubToAdd())\n",
    "model = model.transform(ConvertDivToMul())\n",
    "model = model.transform(collapse.CollapseRepeatedMul())\n",
    "model = model.transform(absorb.AbsorbSignBiasIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbAddIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "\n",
    "model = model.transform(reorder.MoveMulPastMaxPool())\n",
    "model = model.transform(reorder.MoveLinearPastFork())\n",
    "model = model.transform(reorder.MoveLinearPastEltwiseAdd())\n",
    "model = model.transform(reorder.MoveScalarMulPastConv())\n",
    "model = model.transform(reorder.MoveScalarMulPastMatMul())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants()) # for the mul before the global average pool\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbScalarMulAddIntoTopK())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "\n",
    "model = model.transform(RoundAndClipThresholds())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7b375368-73fd-44cd-bed5-20467a14c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8\n",
      "-128\n",
      "input: \"ObTeel\"\n",
      "input: \"YmFg38\"\n",
      "output: \"Add_4_out0\"\n",
      "name: \"Add_5\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"cp54l2\"\n",
      "input: \"hWqriv\"\n",
      "output: \"Add_8_out0\"\n",
      "name: \"Add_9\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"mezOxl\"\n",
      "input: \"IEcTtV\"\n",
      "output: \"Add_14_out0\"\n",
      "name: \"Add_15\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "INT8\n",
      "input: \"3slynj\"\n",
      "input: \"AZByZi\"\n",
      "output: \"Add_18_out0\"\n",
      "name: \"Add_19\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"8MqBTO\"\n",
      "input: \"38p4LG\"\n",
      "output: \"Add_24_out0\"\n",
      "name: \"Add_25\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "INT8\n",
      "input: \"c3qFII\"\n",
      "input: \"xcP2GA\"\n",
      "output: \"Add_28_out0\"\n",
      "name: \"Add_29\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"D0AltB\"\n",
      "input: \"XzfOLZ\"\n",
      "output: \"Add_34_out0\"\n",
      "name: \"Add_35\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "INT8\n",
      "input: \"gJiAze\"\n",
      "input: \"kAyotc\"\n",
      "output: \"Add_38_out0\"\n",
      "name: \"Add_39\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_11: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_18: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_25: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"ObTeel\"\n",
      "input: \"YmFg38\"\n",
      "output: \"Add_4_out0\"\n",
      "name: \"Add_5\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"cp54l2\"\n",
      "input: \"hWqriv\"\n",
      "output: \"Add_8_out0\"\n",
      "name: \"Add_9\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"3slynj\"\n",
      "input: \"AZByZi\"\n",
      "output: \"Add_18_out0\"\n",
      "name: \"Add_19\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"c3qFII\"\n",
      "input: \"xcP2GA\"\n",
      "output: \"Add_28_out0\"\n",
      "name: \"Add_29\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"gJiAze\"\n",
      "input: \"kAyotc\"\n",
      "output: \"Add_38_out0\"\n",
      "name: \"Add_39\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f84a54befe0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CONVERT TO HW\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "model = model.transform(convert.InferPool())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(InferDataLayouts())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "\n",
    "model = tidy_up(model)\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f12a0baf-9998-4ea8-9cd2-f1fe965692c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found topk node\n"
     ]
    }
   ],
   "source": [
    "import finn.transformation.streamline.reorder as reorder\n",
    "\n",
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8e19e491-b8fd-42c1-8cb2-db777b67b25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff579033e50>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "94f757fc-9f61-4ec4-9dc6-1ea29faf5171",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "streamlined = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "080b312d-3de0-48a1-b79e-644bd85e89d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff575787df0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(InferDataLayouts()) # infer data layouts is a lifesaver\n",
    "model = model.transform(convert.InferGlobalAccPoolLayer())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "e1b03bc0-c247-462b-9d87-2784924c3c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff574916830>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(convert.InferPool())\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7836196e-9a36-4d8f-a93a-83db63803653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5788b2fb0>"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoFlatten())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "7dcecb9e-318d-43e2-97dd-7a76027483de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5748084c0>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(reorder.MoveScalarLinearPastInvariants())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ea5af60b-8269-4f33-9a4a-0455867e662a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57480ac50>"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(absorb.AbsorbMulIntoMultiThreshold())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "843487b3-fa6d-40d2-82de-33fae8f08b18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INT8\n",
      "-128\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff57480ba00>"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "543186df-d8db-41fe-b610-42e4347b6744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "43ea2af1-6dfd-4cd6-b2ad-f187c98b7ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "87d41004-dc89-4f07-871b-c75e02901ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "ec95fc36-65e5-4e93-931a-2ccff9878048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "dabb2305-0ed1-4b2a-acf6-5e0213717844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5754cfb20>"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "4d525af5-055b-46c8-bb75-3f5dce97b6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff7524d1ae0>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "9bf2e596-91bd-4120-9853-3a8adb58f10e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff575668910>"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "edd6c99b-be48-4e74-b936-8ef6798a7786",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_11: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_18: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n",
      "/srv/homes/ipanagou/thesis/finn/src/finn/custom_op/fpgadataflow/thresholding.py:84: UserWarning: inputDataType changing for Thresholding_MultiThreshold_25: INT32 -> INT9 \n",
      "  warnings.warn(warn_str)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff5747e7880>"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "57527cc3-c082-4012-b9c4-c94b26e1f450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff7524d31f0>"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "d9448518-4a80-4451-a195-75ba06084f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input: \"Thresholding_3_out0\"\n",
      "input: \"DuplicateStreams_0_out1\"\n",
      "output: \"Add_0_out0\"\n",
      "name: \"Add_0\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_6_out0\"\n",
      "input: \"DuplicateStreams_1_out1\"\n",
      "output: \"Add_1_out0\"\n",
      "name: \"Add_1\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_13_out0\"\n",
      "input: \"DuplicateStreams_3_out1\"\n",
      "output: \"Add_2_out0\"\n",
      "name: \"Add_2\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_20_out0\"\n",
      "input: \"DuplicateStreams_5_out1\"\n",
      "output: \"Add_3_out0\"\n",
      "name: \"Add_3\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "input: \"Thresholding_27_out0\"\n",
      "input: \"DuplicateStreams_7_out1\"\n",
      "output: \"Add_4_out0\"\n",
      "name: \"Add_4\"\n",
      "op_type: \"Add\"\n",
      "\n",
      "INT8\n",
      "UINT8\n",
      "different data types\n",
      "Stopping http://0.0.0.0:8081\n",
      "Serving 'model.onnx' at http://0.0.0.0:8081\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"400\"\n",
       "            src=\"http://localhost:8081/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7ff577eb5270>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = tidy_up(model)\n",
    "model = model.transform(convert.InferAddStreamsLayer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de8119f-07c2-4b1b-a2a8-6f9646380587",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bb1906-5007-4736-8702-1d5a98ef60fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe6bfa3-bcd6-4b9a-8e1e-1a7977c61e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da744171-26d2-46d4-bfde-6b27410579bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f4b716-5672-47d3-b287-c522498022ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26de2f-5479-4413-874f-c17e6c28bd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91d84a8-a8fd-4b74-84a9-c83eda169208",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(convert.InferPool())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb57a8e-3671-4f5a-aebc-4d44a4745219",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665a20d9-3fee-4b5d-80cd-d5946c87a6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "#model.save('model.onnx')\n",
    "#showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdcb642-8a07-4d82-aed6-e85108bf842f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(LowerConvsToMatMul())\n",
    "model = model.transform(convert.InferChannelwiseLinearLayer())\n",
    "model = model.transform(convert.InferConvInpGen())\n",
    "model = model.transform(convert.InferQuantizedMatrixVectorActivation())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54a1c03-a79c-4765-838e-a004755879f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_model = deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fd5b17-5dac-4920-ab7c-adb3c7bfb327",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0feb1-d49a-4179-8325-a72529fe65e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(reorder.MoveTransposePastJoinAdd())\n",
    "model = model.transform(absorb.AbsorbTransposeIntoMultiThreshold())\n",
    "model = model.transform(reorder.MoveTransposePastFork())\n",
    "model = model.transform(absorb.AbsorbConsecutiveTransposes())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a3bf3e-4b05-4d24-a9d9-6a59c4398663",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.transform(convert.InferAddStreamsLayer())\n",
    "model = model.transform(convert.InferDuplicateStreamsLayer())\n",
    "model = model.transform(convert.InferThresholdingLayer())\n",
    "model = model.transform(RemoveCNVtoFCFlatten())\n",
    "model = model.transform(convert.InferLabelSelectLayer())\n",
    "model.save('model.onnx')\n",
    "showInNetron('model.onnx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
